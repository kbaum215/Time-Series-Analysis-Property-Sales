---
title: "Data_Preprocessing_ADS506Proj"
author: "Kevin Baum"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load in the data
```{r}
library(readr)
library(caret)
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggplot2)
library(forecast)
data <- read_csv("raw_sales.csv")
head(data)
```

Check for missing values:
```{r}
colSums(is.na(data))
```


```{r}
ggplot(data, aes(x = propertyType, y = price)) + 
  geom_boxplot()
```

Below, we filter out the outliers based on interquartile ranges using the standard principle of 1.5 times the lowest and highest quartile. We then display the number of rows with outliers to see how many there are:
```{r}
Q1 <- quantile(data$price, 0.25)
Q3 <- quantile(data$price, 0.75)
IQR <- IQR(data$price)
outliers <- subset(data, price < (Q1 - 1.5 * IQR) | price > (Q3 + 1.5 * IQR))
nrow(outliers)
```

Below: we show the total amount of rows:
```{r}
nrow(data)
```

Next, we remove outliers:
```{r}
clean_data <- subset(data, price >= (Q1 - 1.5 * IQR) & price <= (Q3 + 1.5 * IQR))
nrow(clean_data)
```

Next we show the boxplots of prices after removing outliers
```{r}
ggplot(clean_data, aes(x = propertyType, y = price)) + 
  geom_boxplot()
```


```{r}
# Convert dates to year-month format

# Convert dates to year-month format
data <- data %>%
  mutate(datesold = floor_date(as.Date(datesold), "month"))
```


```{r}
# Aggregate data to monthly level
monthly_data <- data %>%
  group_by(datesold) %>%
  summarize(price = mean(price)) # or use another aggregation function as needed

head(monthly_data)
```








```{r}
# Find the latest date to get the split point
latest_date <- max(monthly_data$datesold, na.rm = TRUE)

# Display the latest date
latest_date
```




Next, we perform data splitting
```{r}
# Splitting the data into training and testing sets
set.seed(123) 

# Determine the split point to get 12 months of data before the latest date
split_date <- latest_date - 365

# Perform the split
train_data <- filter(monthly_data, datesold <= split_date)
test_data <- filter(monthly_data, datesold > split_date)

# Displaying the number of rows in training and testing
nrow(train_data)
nrow(test_data)
```

Smoothing: The point of smoothing is to smooth out short term fluctuations and highlight longer-term trends. There are different smoothing methods, and the one we use is "moving average." The window_size variable is the number of periods that the smoothing average will consider and is set to 10 as a default. A smaller value for window_size will follow the data more closely but retain more noise while a larger value will be smoother and eliminate more noise but follow the data less closely.

The Moving Average smoothing method is chosen for its simplicity, interpretability, and common use case. It is easy to understand by users that new data will affect what is already being seen but should be understood as part of the average trend when thinking holistically about patterns in a time series. One downside to be aware of is lag time. If we were talking about a moving average of a stock series, for instance, and took a 5 year trend in April of 2020, we would not be accurately capturing what was happening in the stock market during the start of the COVID19 pandemic when the S and P 500 dropped 30% in a month. 
```{r}
# Smoothing using a Moving Average
window_size <- 10  
monthly_data <- monthly_data %>%
  mutate(price_smoothed = zoo::rollapply(price, width = window_size, FUN = mean, fill = NA, align = "center"))
```


Differencing: The point of differencing is to transform the price column into a series where each value is the difference from its previous value. This makes the series more stationary.
```{r}
# Differencing the series
monthly_data <- monthly_data %>%
  mutate(price_diff = c(NA, diff(price)))
```



```{r}
# Plotting
# Original Price
ggplot(monthly_data, aes(x = datesold, y = price)) +
  geom_line() +
  labs(title = "Original Price", x = "Date", y = "Price")

# Smoothed Price
ggplot(monthly_data, aes(x = datesold, y = price_smoothed)) +
  geom_line(color = "blue") +
  labs(title = "Smoothed Price (Moving Average)", x = "Date", y = "Smoothed Price")

# Differenced Price
ggplot(monthly_data, aes(x = datesold, y = price_diff)) +
  geom_line(color = "red") +
  labs(title = "Differenced Price", x = "Date", y = "Differenced Price")
```


```{r}
start_year <- year(min(train_data$datesold))
start_month <- month(min(train_data$datesold))

```

```{r}
# Convert training data to a time series object
# train_ts <- ts(train_data$price, frequency = 12)
# Convert training data to a time series object
train_ts <- ts(train_data$price, start=c(start_year, start_month), frequency=12)


# Apply Holt-Winters Exponential Smoothing
hw_model <- HoltWinters(train_ts)

# Summary of the model
summary(hw_model)
```


```{r}
# Check model diagnostics
plot(hw_model)
```


```{r}
# Forecast using the Holt-Winters model
hw_forecast <- forecast(hw_model, h = 12)

# Plot the forecast
plot(hw_forecast)
```

```{r}
end_train_year <- year(max(train_data$datesold))
end_train_month <- month(max(train_data$datesold))

```


```{r}
# Adjust for rolling over to the next year
if (end_train_month == 12) {
  start_test_year <- end_train_year + 1
  start_test_month <- 1
} else {
  start_test_year <- end_train_year
  start_test_month <- end_train_month + 1
}

# Convert test data to a time series object
test_ts <- ts(test_data$price, start=c(start_test_year, start_test_month), frequency=12)
```

```{r}
hw_forecast
```

```{r}
test_ts
```


```{r}
print(hw_forecast)
print(test_ts)
```


```{r}
# Calculate accuracy metrics
accuracy(hw_forecast, test_ts)
```

